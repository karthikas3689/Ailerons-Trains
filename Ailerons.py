# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/105Ov01KHlXEBfmlLmgkwDsr26hug_6s3

# project1

Use the "Run" button to execute the code.
"""

!pip install numpy --quiet

"""## Installing the Libraries in Jupyter Notebook"""

!pip install pandas-profiling numpy matplotlib seaborn --quiet

!pip install opendatasets scikit-learn --quiet --upgrade

"""### Downloading the Dataset"""

import opendatasets as od
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
import os

od.download('https://drive.google.com/file/d/1_7F-fwRKINqeH1NlLQ-fAqxtEe3BvYTq/view?usp=sharing')

data_df=pd.read_csv('ailerons_train.csv')

"""### Given Dataset """

data_df

"""### Statistical analysis of Dataset"""

data_df.describe()

"""### Columns of Dataset"""

data_df.columns

"""### Missing values in Dataset"""

data_df.info()

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline

sns.set_style('darkgrid')
#matplotlib.rcParams['font.size'] = 14
#matplotlib.rcParams['figure.figsize'] = (9, 5)
#matplotlib.rcParams['figure.facecolor'] = '#00000000'

"""### Assigning the Input and Target column"""

input_cols = list(data_df.columns)[0:-1]
target_col = 'goal'

inputs = data_df[input_cols].copy()
targets = data_df[target_col].copy()

inputs.isna().sum()

"""### Sample values of inputs"""

inputs.sample(10)

targets.sample(10)

!pip install scikit-learn --upgrade --quiet

"""### Training, Testing and Validation set"""

from sklearn.model_selection import train_test_split

train_val_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)

print('train_df.shape :', train_df.shape)
print('val_df.shape :', val_df.shape)
print('test_df.shape :', test_df.shape)

jovian.commit(project="project1")

train_df

train_inputs = train_df[input_cols].copy()
train_targets = train_df[target_col].copy()

train_inputs

val_inputs = val_df[input_cols].copy()
val_targets = val_df[target_col].copy()

test_inputs = test_df[input_cols].copy()
test_targets = test_df[target_col].copy()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler().fit(inputs)

print('Minimum:')
list(scaler.data_min_)

train_inputs

train_inputs= scaler.transform(train_inputs)
val_inputs = scaler.transform(val_inputs)
test_inputs = scaler.transform(test_inputs)

train_inputs

train_inputs1=pd.DataFrame(train_inputs, columns = [input_cols])

train_inputs1

"""### Statistical Analysis of Training sets"""

train_inputs1.describe()

"""# Linear Regression Model"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()

model.fit(train_inputs1, train_targets)

from sklearn.linear_model import LinearRegression

model = LinearRegression()

train_inputs1

train_targets1 = pd.DataFrame(train_targets)

train_targets1

model.fit(train_inputs1, train_targets1)

#Prediction
train_preds = model.predict(train_inputs)

model.score(train_inputs1, train_targets1)

